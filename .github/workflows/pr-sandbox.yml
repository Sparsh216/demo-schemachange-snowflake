name: PR Sandbox — Snowflake

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main ]   # optional: also validate merges to main

permissions:
  contents: read
  id-token: write   # only used if you enable Azure OIDC for Key Vault

env:
  # Toggle Key Vault via repo variable (Settings → Variables → Actions)
  USE_AZURE_KEYVAULT: ${{ vars.USE_AZURE_KEYVAULT || 'false' }}

jobs:
  sandbox:
    # On PRs: skip if PR is from a fork (no secrets available). On push: always run.
    if: ${{ github.event_name != 'pull_request' || github.event.pull_request.head.repo.fork == false }}
    environment: DEV   # uses DEV environment secrets
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install schemachange==4.0.1 snowflake-connector-python

      # ---------- OPTIONAL: Azure Key Vault (DEV only) ----------
      - name: Azure Login (OIDC)
        if: ${{ env.USE_AZURE_KEYVAULT == 'true' }}
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Pull DEV secrets from Azure Key Vault (optional)
        if: ${{ env.USE_AZURE_KEYVAULT == 'true' }}
        id: kv
        uses: Azure/get-keyvault-secrets@v1
        with:
          keyvault: ${{ secrets.AZURE_KEYVAULT_NAME }}
          secrets: |
            sf-account-dev
            sf-user-dev
            sf-password-dev
            sf-role-dev
            sf-warehouse-dev
            sf-database-dev

      # Resolve connection variables (Key Vault wins; else use DEV env secrets)
      - name: Resolve connection variables
        env:
          GH_SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
          GH_SF_USER:    ${{ secrets.SF_USER }}
          GH_SF_PWD:     ${{ secrets.SF_PWD }}
          GH_SF_ROLE:    ${{ secrets.SF_ROLE }}
          GH_SF_WH:      ${{ secrets.SF_WH }}
          GH_SF_DB:      ${{ secrets.SF_DB }}
        run: |
          acct="${{ steps.kv.outputs['sf-account-dev'] || env.GH_SF_ACCOUNT }}"
          user="${{ steps.kv.outputs['sf-user-dev']    || env.GH_SF_USER }}"
          pwd="${{ steps.kv.outputs['sf-password-dev'] || env.GH_SF_PWD }}"
          role="${{ steps.kv.outputs['sf-role-dev']    || env.GH_SF_ROLE }}"
          wh="${{ steps.kv.outputs['sf-warehouse-dev'] || env.GH_SF_WH }}"
          db="${{ steps.kv.outputs['sf-database-dev']  || env.GH_SF_DB }}"

          # Trim + export, and mask sensitive values
          for k in acct user pwd role wh db; do
            v="$(eval echo \$$k | xargs)"
            [ "$k" = "pwd" ] && echo "::add-mask::$v"
            echo "$(echo $k | tr a-z A-Z)_RESOLVED=$v" >> $GITHUB_ENV
          done

      - name: Write connections.toml
        run: |
          mkdir -p ~/.snowflake
          cat > ~/.snowflake/connections.toml << EOF
          [ci]
          account   = "${ACCT_RESOLVED}"
          user      = "${USER_RESOLVED}"
          role      = "${ROLE_RESOLVED}"
          warehouse = "${WH_RESOLVED}"
          database  = "${DB_RESOLVED}"
          password  = "${PWD_RESOLVED}"
          EOF
          chmod 600 ~/.snowflake/connections.toml

      # Compute sandbox DB name and expose it to later steps
      - name: Compute sandbox name
        id: names
        run: |
          ts=$(date +%Y%m%d%H%M%S)
          echo "db=SBX_${ts}_${GITHUB_RUN_ID}" >> "$GITHUB_OUTPUT"

      - name: Create sandbox DB
        env:
          SANDBOX_DB: ${{ steps.names.outputs.db }}
        run: |
          python - <<'PY'
          import os, snowflake.connector
          con = snowflake.connector.connect(
            account=os.environ['ACCT_RESOLVED'],
            user=os.environ['USER_RESOLVED'],
            password=os.environ['PWD_RESOLVED'],
            warehouse=os.environ['WH_RESOLVED'],
            role=os.environ['ROLE_RESOLVED'],
          )
          cs = con.cursor()
          db = os.environ['SANDBOX_DB']
          cs.execute(f"CREATE DATABASE IF NOT EXISTS {db}")
          cs.execute(f"CREATE SCHEMA IF NOT EXISTS {db}.PUBLIC")
          cs.close(); con.close()
          PY

      - name: Dry run in sandbox
        env:
          SANDBOX_DB: ${{ steps.names.outputs.db }}
        run: |
          schemachange \
            -f migrations \
            -c "${SANDBOX_DB}.PUBLIC.CHANGE_HISTORY" \
            --dry-run \
            --create-change-history-table \
            --connection-name ci

      - name: Apply to sandbox
        env:
          SANDBOX_DB: ${{ steps.names.outputs.db }}
        run: |
          schemachange \
            -f migrations \
            -c "${SANDBOX_DB}.PUBLIC.CHANGE_HISTORY" \
            --create-change-history-table \
            --connection-name ci

      - name: Teardown sandbox (always)
        if: always()
        env:
          SANDBOX_DB: ${{ steps.names.outputs.db }}
        run: |
          python - <<'PY'
          import os, snowflake.connector
          con = snowflake.connector.connect(
            account=os.environ['ACCT_RESOLVED'],
            user=os.environ['USER_RESOLVED'],
            password=os.environ['PWD_RESOLVED'],
            warehouse=os.environ['WH_RESOLVED'],
            role=os.environ['ROLE_RESOLVED'],
          )
          cs = con.cursor()
          cs.execute(f"DROP DATABASE IF EXISTS {os.environ['SANDBOX_DB']}")
          cs.close(); con.close()
          PY
